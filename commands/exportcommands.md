# /exportcommands - Export Claude Commands to Reference Repository

üö® **CRITICAL SUCCESS REQUIREMENT**: This command MUST always print the export PR URL as the final output. The command is NOT complete without providing the PR URL to the user.

üö® **REPOSITORY SAFETY RULE**: Export operations NEVER delete, move, or modify files in the current repository. Export only copies files for external sharing. The current repository remains completely unchanged.

**Purpose**: Export your complete command composition system to https://github.com/jleechanorg/claude-commands for reference and sharing

**Implementation**: This command delegates all technical operations to the Python implementation (`exportcommands.py`) while providing LLM-driven README generation and intelligent export analysis.

**Usage**: `/exportcommands` - Executes complete export pipeline with automated PR creation

## üéØ COMMAND COMPOSITION ARCHITECTURE

**The Simple Hook That Changes Everything**: At its core, `/exportcommands` is just a file export script. But what makes it powerful is that it's exporting a complete **command composition system** that transforms how you interact with Claude Code.

### Multi-Command Workflows Made Simple

**Before**: Manual step-by-step development
```
1. Analyze the issue manually
2. Write code manually
3. Test manually
4. Create PR manually
5. Handle review comments manually
```

**After**: Single command workflows
```bash
/pr "fix authentication bug"     # ‚Üí analyze ‚Üí implement ‚Üí test ‚Üí create PR
/copilot                        # ‚Üí comprehensive PR analysis ‚Üí apply all fixes
/execute "add user dashboard"   # ‚Üí plan ‚Üí implement ‚Üí test ‚Üí document
```

### The Composition Pattern

Each command is designed to **compose** with others through a shared protocol:
- **TodoWrite Integration**: Commands break down into trackable steps
- **Memory Enhancement**: Learning from previous executions
- **Git Workflow Integration**: Automatic branch management and PR creation
- **Testing Integration**: Automatic test running and validation
- **Error Recovery**: Smart handling of failures and retries

### Key Compositional Commands Being Exported

**Workflow Orchestrators**:
- `/pr` - Complete PR workflow (analyze ‚Üí fix ‚Üí test ‚Üí create)
- `/copilot` - Autonomous PR analysis and fixing
- `/execute` - Auto-approval development with TodoWrite tracking
- `/orch` - Multi-agent task delegation system

**Building Blocks**:
- `/think` + `/arch` + `/debug` = Cognitive analysis chain
- `/test` + `/fix` + `/verify` = Quality assurance chain
- `/plan` + `/implement` + `/validate` = Development chain

**The Hook Architecture**: Simple `.md` files that Claude Code reads as executable instructions, enabling complex behavior through composition rather than complexity.

## ‚ö° COMMAND COMBINATION SUPERPOWERS

### Combine Multiple Commands in a Single Prompt

**Revolutionary Feature**: Normally, Claude can only handle one command per sentence. This tool lets you string them together in a single prompt, creating sophisticated multi-step workflows.

**Example**: Give this PR a thorough code review with `/archreview /thinkultra /fake`

This runs:
1. `/archreview` - Architectural analysis of the codebase
2. `/thinkultra` - Deep strategic thinking about the changes  
3. `/fake` - Detection of placeholder or incomplete code

**The Foundation**: This command combination capability is the foundation for creating more complex, multi-step workflows that would normally require multiple separate interactions.

### Automate Your PR Lifecycle

**Complete Automation**: You can automate your entire pull request workflow with natural language commands.

**Example**: `/pr fix the settings button`

This automatically runs the whole sequence:
- `/think` - Strategic analysis of the settings button issue
- `/execute` - Implementation with auto-approval
- `/push` - Create PR with comprehensive description
- `/copilot` - Respond to GitHub comments and make fixes
- `/review` - Claude's own comprehensive code review

**The `/copilot` Advantage**: The `/copilot` command even responds to GitHub comments and makes fixes automatically, handling the entire feedback loop without manual intervention.

### Detect Fake Code with AI Analysis

**Quality Assurance**: Built-in detection for "fake" code that Claude sometimes generates when pushed too hard.

**The Problem**: When overloaded, Claude sometimes writes placeholder code instead of implementing what you asked for - like just returning success without actual logic.

**The Solution**: If something seems off, run the `/fake` command to systematically detect:
- Placeholder implementations  
- Mock responses without real logic
- TODOs disguised as complete features
- Demo code that doesn't actually work

**Smart Detection**: This isn't just pattern matching - it's AI-powered analysis that understands the difference between legitimate code and fake implementations.

## üîç COMMAND DEEP DIVE - The Composition Powerhouses

### `/execute` - Auto-Approval Development Orchestrator

**What It Does**: The ultimate autonomous development command that handles everything from planning to implementation with built-in auto-approval.

**The Magic**: Turns complex development tasks into structured, trackable workflows without manual approval gates.

**Composition Architecture**:
```bash
/execute "implement user authentication"
```

**Internal Workflow**:
1. **Phase 1 - Planning**:
   - Complexity assessment (simple/medium/complex)
   - Execution method decision (parallel vs sequential)
   - Tool requirements analysis
   - Timeline estimation
   - Implementation approach design

2. **Phase 2 - Auto-Approval**:
   - Built-in approval bypass: "User already approves - proceeding with execution"
   - No manual intervention required

3. **Phase 3 - TodoWrite Orchestration**:
   - Breaks task into trackable steps
   - Real-time progress updates
   - Error handling and recovery
   - Completion verification

**Real Example** (This very task demonstrates `/execute`):
```
User: /execute "focus on command composition and explain details on /execute..."
Claude:
  Phase 1 - Planning: [complexity assessment, timeline, approach]
  Phase 2 - Auto-approval: "User already approves - proceeding"
  Phase 3 - Implementation: [TodoWrite tracking, step execution]
```

### `/plan` - Manual Approval Development Planning

**What It Does**: Structured development planning with explicit user approval required before execution.

**The Magic**: Perfect for complex tasks where you want to review the approach before committing resources.

**Composition Architecture**:
```bash
/plan "redesign authentication system"
```

**Workflow**:
1. **Deep Analysis**: Research existing system, identify constraints, analyze requirements
2. **Multi-Approach Planning**: Present 2-3 different implementation approaches
3. **Resource Assessment**: Timeline, complexity, tool requirements, risk analysis
4. **Approval Gate**: User must explicitly approve before any implementation begins
5. **Guided Execution**: Step-by-step implementation with checkpoints

**When to Use**:
- Complex architectural changes
- When you want oversight of the approach
- High-risk modifications
- Learning new patterns/technologies

### `/pr` - Complete PR Workflow Orchestrator

**What It Does**: End-to-end PR creation from analysis to submission, handling the entire development lifecycle.

**The Magic**: Single command that handles analysis, implementation, testing, and PR creation autonomously.

**Composition Architecture**:
```bash
/pr "fix authentication validation bug"
```

**Internal Workflow Chain**:
1. **Analysis Phase**:
   - Issue analysis and root cause identification
   - Codebase understanding and impact assessment
   - Solution design and approach selection

2. **Implementation Phase**:
   - Code changes with proper error handling
   - Integration testing and validation
   - Documentation updates

3. **Quality Assurance Phase**:
   - Test execution and verification
   - Code review and quality checks
   - Performance impact assessment

4. **Git Workflow Phase**:
   - Branch creation and management
   - Commit message generation
   - PR creation with detailed description

**Real Workflow Example**:
```
/pr "fix login timeout issue"
‚Üì
Analyze login flow ‚Üí Identify timeout problem ‚Üí Implement fix ‚Üí
Run tests ‚Üí Create branch ‚Üí Commit changes ‚Üí Push ‚Üí Create PR
```

### `/copilot` - Autonomous PR Analysis & Comprehensive Fixing

**What It Does**: Comprehensive PR analysis with autonomous fixing of all detected issues - no approval prompts.

**The Magic**: Scans PRs for every type of issue (conflicts, CI failures, code quality, comments) and fixes everything automatically.

**Composition Architecture**:
```bash
/copilot  # Analyzes current PR context
```

**Autonomous Workflow Chain**:
1. **Comprehensive Scanning**:
   - Merge conflicts detection and resolution
   - CI/CD failure analysis and fixes
   - Code review comment processing
   - Quality gate validation

2. **Intelligent Fixing**:
   - Automated conflict resolution with smart merging
   - Test fixes and dependency updates
   - Code style and formatting corrections
   - Documentation and comment updates

3. **Validation Loop**:
   - Re-run tests after each fix
   - Verify merge status and CI success
   - Continue until all issues resolved

**No Approval Required**: Unlike other commands, `/copilot` operates autonomously - perfect for continuous integration workflows.

**Real Example**:
```
PR has: merge conflicts + failing tests + 5 review comments
/copilot
‚Üì
Resolve conflicts ‚Üí Fix failing tests ‚Üí Address all comments ‚Üí
Re-run validation ‚Üí Push fixes ‚Üí Verify success
```

### `/orch` - Multi-Agent Task Delegation System

**What It Does**: Delegates tasks to autonomous tmux-based agents that work in parallel across different branches and contexts.

**The Magic**: Spawns specialized agents (frontend, backend, testing, opus-master) that execute tasks independently with full Git workflow management.

**Composition Architecture**:
```bash
/orch "implement user dashboard with tests and documentation"
```

**Multi-Agent Workflow**:
1. **Task Analysis & Delegation**:
   - Break complex task into parallel workstreams
   - Assign to specialized agents based on capabilities
   - Create isolated tmux sessions with agent workspaces

2. **Autonomous Agent Execution**:
   - Each agent gets dedicated branch and workspace
   - Independent execution with full development lifecycle
   - Real-time progress monitoring and coordination

3. **Agent Coordination**:
   - Redis-based inter-agent communication
   - Task dependency management
   - Resource allocation and load balancing

4. **Integration & Delivery**:
   - Agent results aggregation
   - PR creation from agent branches
   - Success verification and reporting

**Agent Types**:
- **Frontend Agent**: UI/UX implementation, browser testing, styling
- **Backend Agent**: API development, database integration, server logic
- **Testing Agent**: Test automation, validation, performance testing
- **Opus-Master**: Architecture decisions, code review, integration

**Cost**: $0.003-$0.050 per task (highly efficient)

**Real Example**:
```
/orch "add user notifications system"
‚Üì
Frontend Agent: notification UI components
Backend Agent: notification API endpoints
Testing Agent: notification test suite
Opus-Master: architecture review and integration
‚Üì
All agents work in parallel ‚Üí Create individual PRs ‚Üí Integration verification
```

**Monitoring**:
```bash
/orch monitor agents    # Check agent status
/orch "What's running?" # Current task overview
tmux attach-session -t task-agent-frontend  # Direct agent access
```

## üö® EXPORT PROTOCOL

### Phase 1: Preparation & Validation

**Repository Access Verification**:
- Validate GitHub token and permissions for target repository
- Check if target repository exists and is accessible
- Create local staging directory: `/tmp/claude_commands_export_$(date +%s)/`
- Verify Git configuration for commit operations

**Content Filtering Setup**:
- Initialize comprehensive export filter system with multiple filter types
- Exclude project-specific directories and files (mvp_site/, run_tests.sh, testi.sh)
- Filter out personal/project references (jleechan, worldarchitect.ai, Firebase specifics)
- Transform project-specific paths to generic placeholders
- Set up warning header templates for exported files

### Phase 2: Repository Cleanup & Content Export

**üö® MANDATORY CLEANUP PHASE**: Remove obsolete files that no longer exist in source repository
```bash
# Clone fresh repository from main
export REPO_DIR="/tmp/claude_commands_repo_fresh"
gh repo clone jleechanorg/claude-commands "$REPO_DIR"
cd "$REPO_DIR" && git checkout main

# Create export branch from clean main
export NEW_BRANCH="export-fresh-$(date +%Y%m%d-%H%M%S)"
git checkout -b "$NEW_BRANCH"

# CRITICAL: Clear existing directories for fresh export
rm -rf commands/* orchestration/* scripts/* || true
echo "Cleared existing export directories for fresh sync"
```

**Pre-Export File Filtering**:
```bash
# Create exclusion list for project-specific files
cat > /tmp/export_exclusions.txt << 'EOF'
tests/run_tests.sh
testi.sh
**/test_integration/**
copilot_inline_reply_example.sh
run_ci_replica.sh
testing_http/
testing_ui/
testing_mcp/
ci_replica/
analysis/
automation/
claude-bot-commands/
coding_prompts/
prototype/
EOF

# Filter files before export from staging area
while IFS= read -r pattern; do
    case "$pattern" in
        **/*)
            # Use regex for patterns with ** (recursive directory matching)
            find staging -regextype posix-extended -regex ".*/${pattern#**/}" -exec rm -rf {} + 2>/dev/null || true
            ;;
        *)
            # Use path for simple patterns
            find staging -path "*${pattern}" -exec rm -rf {} + 2>/dev/null || true
            ;;
    esac
    # Also remove root directories that may be copied during main export
    rm -rf "staging/${pattern%/}" 2>/dev/null || true
done < /tmp/export_exclusions.txt
```

**CLAUDE.md Export**:
```bash
# Add reference-only warning header
cat > staging/CLAUDE.md << 'EOF'
# üìö Reference Export - Adaptation Guide

**Note**: This is a reference export from a working Claude Code project. You may need to personally debug some configurations, but Claude Code can easily adjust for your specific needs.

These configurations may include:
- Project-specific paths and settings that need updating for your environment
- Setup assumptions and dependencies specific to the original project
- References to particular GitHub repositories and project structures

Feel free to use these as a starting point - Claude Code excels at helping you adapt and customize them for your specific workflow.

---

EOF

# Filter and append original CLAUDE.md
cp CLAUDE.md /tmp/claude_filtered.md
# Apply content filtering
sed -i 's|mvp_site/|$PROJECT_ROOT/|g' /tmp/claude_filtered.md
sed -i 's|worldarchitect\.ai|your-project.com|g' /tmp/claude_filtered.md
sed -i 's|jleechan|${USER}|g' /tmp/claude_filtered.md
cat /tmp/claude_filtered.md >> staging/CLAUDE.md
```

**Commands Export** (`.claude/commands/` ‚Üí `commands/`):
```bash
# Copy commands with filtering
for file in .claude/commands/*.md .claude/commands/*.py; do
    # Skip project-specific files and template files
    case "$(basename "$file")" in
        "testi.sh"|"run_tests.sh"|"copilot_inline_reply_example.sh"|"README_EXPORT_TEMPLATE.md")
            echo "Skipping project-specific/template file: $file"
            continue
            ;;
    esac

    # Copy and filter content
    cp "$file" "staging/commands/$(basename "$file")"

    # Apply content transformations - completely remove project-specific references
    sed -i 's|mvp_site/|$PROJECT_ROOT/|g' "staging/commands/$(basename "$file")"
    sed -i 's|worldarchitect\.ai|your-project.com|g' "staging/commands/$(basename "$file")"
    sed -i 's|jleechan|${USER}|g' "staging/commands/$(basename "$file")"
    sed -i 's|TESTING=true vpython|TESTING=true python|g' "staging/commands/$(basename "$file")"

    # Remove any remaining project-specific path references
    sed -i 's|/home/${USER}/projects/worldarchitect\.ai/[^/]*||g' "staging/commands/$(basename "$file")"
done
```
- Export filtered command definitions with proper categorization
- Transform hardcoded paths to generic placeholders
- Add compatibility warnings for project-specific commands
- Organize by category: cognitive, operational, testing, development, meta

**Scripts Export** (`claude_command_scripts/` ‚Üí `scripts/`):
```bash
# Export scripts with comprehensive filtering
for script in claude_command_scripts/*.sh claude_command_scripts/*.py; do
    if [[ -f "$script" ]]; then
        script_name=$(basename "$script")

        # Skip project-specific scripts
        case "$script_name" in
            "run_tests.sh"|"testi.sh"|"*integration*")
                echo "Skipping project-specific script: $script_name"
                continue
                ;;
        esac

        # Copy and transform
        cp "$script" "staging/scripts/$script_name"

        # Apply transformations - completely remove project-specific references
        sed -i 's|mvp_site/|$PROJECT_ROOT/|g' "staging/scripts/$script_name"
        sed -i 's|worldarchitect\.ai|your-project.com|g' "staging/scripts/$script_name"
        sed -i 's|/home/${USER}/projects/worldarchitect\.ai/[^/]*||g' "staging/scripts/$script_name"
        sed -i 's|TESTING=true vpython|TESTING=true python|g' "staging/scripts/$script_name"

        # Add dependency header
        sed -i '1i\#!/bin/bash\n# ‚ö†Ô∏è REQUIRES PROJECT ADAPTATION\n# This script contains project-specific paths and may need modification\n' "staging/scripts/$script_name"
    fi
done
```
- Export script implementations with dependency documentation
- Transform mvp_site paths to generic PROJECT_ROOT placeholders
- Add setup requirements documentation for each script
- Include execution environment requirements

**üö® Hooks Export** (`.claude/hooks/` ‚Üí `hooks/`) - **ESSENTIAL CLAUDE CODE FUNCTIONALITY**:
```bash
# Export Claude Code hooks with comprehensive filtering
echo "üìé Exporting Claude Code hooks..."

# Create hooks destination directory
mkdir -p staging/hooks

# Check if source hooks directory exists
if [[ ! -d ".claude/hooks" ]]; then
    echo "‚ö†Ô∏è  Warning: .claude/hooks directory not found - skipping hooks export"
else
    echo "üìÅ Found .claude/hooks directory - proceeding with export"

    # Enable nullglob to handle cases where no files match patterns
    shopt -s nullglob

    # Export hook scripts with filtering (including nested subdirectories)
    find .claude/hooks -type f \( -name "*.sh" -o -name "*.py" -o -name "*.md" \) -print0 | while IFS= read -r -d '' hook_file; do
        hook_name=$(basename "$hook_file")
        relative_path="${hook_file#.claude/hooks/}"

        # Skip test and example files
        case "$hook_name" in
            *test*|*example*|debug_hook.sh)
                echo "   ‚è≠ Skipping $hook_name (test/debug file)"
                continue
                ;;
        esac

        echo "   üìé Copying: $relative_path"

        # Create subdirectory structure if needed
        hook_dir=$(dirname "staging/hooks/$relative_path")
        mkdir -p "$hook_dir"

        # Copy and transform hook files
        cp "$hook_file" "staging/hooks/$relative_path"

        # Apply comprehensive content transformations
        sed -i 's|mvp_site/|$PROJECT_ROOT/|g' "staging/hooks/$relative_path"
        sed -i 's|worldarchitect\.ai|your-project.com|g' "staging/hooks/$relative_path"
        sed -i 's|jleechan|${USER}|g' "staging/hooks/$relative_path"
        sed -i 's|TESTING=true vpython|TESTING=true python|g' "staging/hooks/$relative_path"
        sed -i 's|/home/${USER}/projects/worldarchitect\.ai/[^/]*||g' "staging/hooks/$relative_path"

        # Make scripts executable and add adaptation headers
        case "$hook_name" in
            *.sh)
                chmod +x "staging/hooks/$relative_path"
                # Add adaptation header only if file doesn't start with shebang
                if ! head -1 "staging/hooks/$relative_path" | grep -q '^#!'; then
                    sed -i '1i\#!/bin/bash\n# üö® CLAUDE CODE HOOK - ESSENTIAL FUNCTIONALITY\n# ‚ö†Ô∏è REQUIRES PROJECT ADAPTATION - Contains project-specific configurations\n# This hook provides core Claude Code workflow automation\n# Adapt paths and project references for your environment\n' "staging/hooks/$relative_path"
                else
                    sed -i '1a\# üö® CLAUDE CODE HOOK - ESSENTIAL FUNCTIONALITY\n# ‚ö†Ô∏è REQUIRES PROJECT ADAPTATION - Contains project-specific configurations\n# This hook provides core Claude Code workflow automation\n# Adapt paths and project references for your environment\n' "staging/hooks/$relative_path"
                fi
                ;;
            *.py)
                chmod +x "staging/hooks/$relative_path"
                # Add adaptation note after any existing shebang
                if head -1 "staging/hooks/$relative_path" | grep -q '^#!'; then
                    sed -i '1a\# üö® CLAUDE CODE HOOK - ESSENTIAL FUNCTIONALITY\n# ‚ö†Ô∏è REQUIRES PROJECT ADAPTATION - Contains project-specific configurations\n# This hook provides core Claude Code workflow automation\n# Adapt imports and project references for your environment\n' "staging/hooks/$relative_path"
                else
                    sed -i '1i\# üö® CLAUDE CODE HOOK - ESSENTIAL FUNCTIONALITY\n# ‚ö†Ô∏è REQUIRES PROJECT ADAPTATION - Contains project-specific configurations\n# This hook provides core Claude Code workflow automation\n# Adapt imports and project references for your environment\n' "staging/hooks/$relative_path"
                fi
                ;;
        esac
    done

    # Restore nullglob setting
    shopt -u nullglob

    # Note: Subdirectories are now handled by the find loop above

    echo "‚úÖ Hooks export completed successfully"
fi
```
- **üîß Core Claude Code Functionality**: Essential hooks that enable automatic workflow management
- **PreToolUse Hooks**: Code quality validation before file operations (anti_demo_check_claude.sh, check_root_files.sh)
- **PostToolUse Hooks**: Automated sync after git operations (post_commit_sync.sh)
- **PostResponse Hooks**: Response quality validation (detect_speculation_and_fake_code.sh)
- **Command Composition**: Hook utilities for advanced workflow orchestration (compose-commands.sh)
- **Testing Framework**: Complete hook testing utilities for validation and debugging
- **Project Adaptation**: Comprehensive filtering of project-specific paths and references
- **Executable Permissions**: Automatic permission setting for shell scripts
- **Documentation**: Clear adaptation requirements and functionality descriptions

**üö® Root-Level Infrastructure Scripts Export** (Root ‚Üí `infrastructure-scripts/`):
```bash
# Export development environment infrastructure scripts
mkdir -p staging/infrastructure-scripts

# Dynamically discover valuable root-level scripts to export
mapfile -t ROOT_SCRIPTS < <(ls -1 *.sh 2>/dev/null | grep -E '^(claude_|start-claude-bot|integrate|resolve_conflicts|sync_branch|setup-github-runner|test_server_manager)\.sh$')

for script_name in "${ROOT_SCRIPTS[@]}"; do
    if [[ -f "$script_name" ]]; then
        echo "Exporting infrastructure script: $script_name"

        # Copy and transform
        cp "$script_name" "staging/infrastructure-scripts/$script_name"

        # Apply comprehensive content transformations
        sed -i 's|/tmp/worldarchitect\.ai|/tmp/$PROJECT_NAME|g' "staging/infrastructure-scripts/$script_name"
        sed -i 's|worldarchitect-memory-backups|$PROJECT_NAME-memory-backups|g' "staging/infrastructure-scripts/$script_name"
        sed -i 's|worldarchitect\.ai|your-project.com|g' "staging/infrastructure-scripts/$script_name"
        sed -i 's|jleechan|$USER|g' "staging/infrastructure-scripts/$script_name"
        sed -i 's|D&D campaign management|Content management|g' "staging/infrastructure-scripts/$script_name"
        sed -i 's|Game MCP Server|Content MCP Server|g' "staging/infrastructure-scripts/$script_name"
        sed -i 's|start_game_mcp\.sh|start_content_mcp.sh|g' "staging/infrastructure-scripts/$script_name"

        # Add infrastructure script header with adaptation warning
        sed -i '1i\#!/bin/bash\n# üö® DEVELOPMENT INFRASTRUCTURE SCRIPT\n# ‚ö†Ô∏è REQUIRES PROJECT ADAPTATION - Contains project-specific configurations\n# This script provides development environment management patterns\n# Adapt paths, service names, and configurations for your project\n\n' "staging/infrastructure-scripts/$script_name"
    else
        echo "Warning: Infrastructure script not found: $script_name"
    fi
done
```
- Export complete development environment bootstrap and management scripts
- Transform project-specific service names and paths to generic placeholders
- Include comprehensive setup and adaptation documentation
- Document multi-service management patterns (MCP servers, orchestration, bot servers)

**üö® Orchestration System Export** (`orchestration/` ‚Üí `orchestration/`) - **WIP PROTOTYPE**:
- Export complete multi-agent task delegation system with Redis coordination
- **Architecture**: tmux-based agents (frontend, backend, testing, opus-master) with A2A communication
- **Usage**: `/orch [task]` for autonomous delegation, costs $0.003-$0.050/task
- **Requirements**: Redis server, tmux, Python venv, specialized agent workspaces
- Document autonomous workflow: task creation ‚Üí agent assignment ‚Üí execution ‚Üí PR creation
- Include monitoring via `/orch monitor agents` and direct tmux attachment procedures
- Add scaling guidance for agent capacity and workload distribution
- **Status**: Active development prototype - successful task completion verified with PR generation


**Configuration Export**:
- Export relevant config files (filtered for sensitive data)
- Include setup templates and environment examples
- Document MCP server requirements and configuration
- Provide installation verification procedures

## IMPLEMENTATION

**üö® DELEGATION TO PYTHON IMPLEMENTATION**: All technical export operations are handled by the robust Python implementation (`exportcommands.py`), while this command focuses on LLM-driven analysis and README generation.

### Step 1: Analyze Current Command System State

First, let me analyze the current state of the command system to provide intelligent README generation:

```python
# Analyze the current .claude/commands directory
import os
import subprocess

# Get project root
result = subprocess.run(['git', 'rev-parse', '--show-toplevel'], capture_output=True, text=True)
project_root = result.stdout.strip()

# Count commands, hooks, and scripts
commands_dir = os.path.join(project_root, '.claude', 'commands')
hooks_dir = os.path.join(project_root, '.claude', 'hooks')

commands_count = len([f for f in os.listdir(commands_dir) if f.endswith(('.md', '.py'))])
hooks_count = sum([len([f for f in files if f.endswith(('.sh', '.py', '.md'))])
                   for root, dirs, files in os.walk(hooks_dir)])

print(f"üìä Analysis: {commands_count} commands, {hooks_count} hooks detected")
```

### Step 2: Execute Python Implementation

```python
# Execute the comprehensive Python implementation
python_script = os.path.join(project_root, '.claude', 'commands', 'exportcommands.py')
result = subprocess.run([python_script], capture_output=True, text=True)

if result.returncode != 0:
    print(f"‚ùå Export failed: {result.stderr}")
    exit(1)

print(result.stdout)
```

### Step 3: LLM-Enhanced README Generation (PRESERVED CAPABILITY)

While the Python implementation generates a comprehensive README, this LLM can provide additional intelligent analysis:

**Command Pattern Analysis**: Analyze which commands are compositional powerhouses
```python
# Identify key workflow orchestrators vs building blocks
compositional_commands = ['pr.md', 'copilot.md', 'execute.md', 'orch.md']
building_blocks = ['think.md', 'test.md', 'fix.md', 'plan.md']

print("üéØ Workflow Orchestrators:", compositional_commands)
print("üß± Building Blocks:", building_blocks)
```

**Usage Pattern Insights**: Generate intelligent insights about command relationships
```python
# Analyze command interdependencies
print("üìä Command Composition Patterns:")
print("- /pr ‚Üí /think ‚Üí /execute ‚Üí /pushl ‚Üí /copilot ‚Üí /review")
print("- /copilot ‚Üí /execute ‚Üí /commentfetch ‚Üí /fixpr ‚Üí /commentreply")
print("- /execute ‚Üí /plan ‚Üí /think ‚Üí implementation ‚Üí /test")
```

## EXECUTION

**üöÄ PRIMARY EXECUTION PATH**: Use the Python implementation for reliable export
```bash
python3 .claude/commands/exportcommands.py
```

**üß† LLM ENHANCEMENT CAPABILITIES**:
- Generate contextual README sections based on current command inventory
- Analyze command composition patterns for documentation
- Provide intelligent adaptation guidance for different project types
- Generate usage examples tailored to the exported command set

## IMPLEMENTATION EXECUTION

Let me now execute the export using the Python implementation:

```python
import os
import subprocess

# Execute the Python implementation
project_root = subprocess.run(['git', 'rev-parse', '--show-toplevel'],
                            capture_output=True, text=True).stdout.strip()
python_script = os.path.join(project_root, '.claude', 'commands', 'exportcommands.py')

print("üöÄ Starting export via Python implementation...")
result = subprocess.run(['python3', python_script], capture_output=True, text=True)

if result.returncode \!= 0:
    print(f"‚ùå Export failed: {result.stderr}")
    exit(1)

# Print the output (including the critical PR URL)
print(result.stdout)
```

**üö® CRITICAL**: The above execution will print the PR URL as the final output, fulfilling the critical success requirement.

## POST-EXPORT ANALYSIS

After the Python implementation completes, provide intelligent analysis:

```python
# Analyze export results for documentation enhancement
print("\nüìä Export Analysis:")
print("‚úÖ Command composition system exported successfully")
print("‚úÖ Directory exclusions applied per requirements")
print("‚úÖ Content filtering applied for project portability")
print("‚úÖ One-click installation script generated")
print("‚úÖ Comprehensive README with adaptation guide created")
```
# Analyze the current .claude/commands directory
import os
import subprocess

# Get project root
result = subprocess.run(['git', 'rev-parse', '--show-toplevel'], capture_output=True, text=True)
project_root = result.stdout.strip()

# Count commands, hooks, and scripts
commands_dir = os.path.join(project_root, '.claude', 'commands')
hooks_dir = os.path.join(project_root, '.claude', 'hooks')

commands_count = len([f for f in os.listdir(commands_dir) if f.endswith(('.md', '.py'))])
hooks_count = sum([len([f for f in files if f.endswith(('.sh', '.py', '.md'))])
                   for root, dirs, files in os.walk(hooks_dir)])

print(f"üìä Analysis: {commands_count} commands, {hooks_count} hooks detected")
```

### Step 2: Execute Python Implementation

```python
# Execute the comprehensive Python implementation
python_script = os.path.join(project_root, '.claude', 'commands', 'exportcommands.py')
result = subprocess.run([python_script], capture_output=True, text=True)

if result.returncode != 0:
    print(f"‚ùå Export failed: {result.stderr}")
    exit(1)

print(result.stdout)
```

### Step 3: LLM-Enhanced README Generation with Version Intelligence

üö® **VERSION GENERATION BY LLM**: The LLM now intelligently generates version numbers and change summaries rather than mechanical Python incrementing.

**LLM Version Analysis Process**:
1. **Examine Previous Version**: Check target repo's current README for last version
2. **Analyze Git History**: Review recent commits since last export
3. **Determine Version Bump**:
   - **Patch (x.x.1)**: Bug fixes, minor updates, documentation
   - **Minor (x.1.0)**: New features, significant enhancements
   - **Major (1.0.0)**: Breaking changes, major architecture shifts
4. **Generate Change Summary**: Create meaningful bullet points based on actual changes
5. **Update README_EXPORT_TEMPLATE.md**: Fill LLM_VERSION placeholders with intelligent content

üö® **CRITICAL ENHANCEMENT**: The export README must showcase the revolutionary command combination capabilities, not just be a basic file listing.

**Enhanced README Requirements**:
- **‚ö° COMMAND COMBINATION SUPERPOWERS** section prominently featured
- Multi-command workflow examples (`/archreview /thinkultra /fake`)
- Complete PR lifecycle automation documentation (`/pr fix the settings button`)
- AI-powered fake code detection capabilities
- Quick start examples and advanced workflow patterns
- Professional setup guide with practical value proposition

While the Python implementation generates a comprehensive README, this LLM can provide additional intelligent analysis:

**Command Pattern Analysis**: Analyze which commands are compositional powerhouses
```python
# Identify key workflow orchestrators vs building blocks
compositional_commands = ['pr.md', 'copilot.md', 'execute.md', 'orch.md']
building_blocks = ['think.md', 'test.md', 'fix.md', 'plan.md']

print("üéØ Workflow Orchestrators:", compositional_commands)
print("üß± Building Blocks:", building_blocks)
```

**Usage Pattern Insights**: Generate intelligent insights about command relationships
```python
# Analyze command interdependencies
print("üìä Command Composition Patterns:")
print("- /pr ‚Üí /think ‚Üí /execute ‚Üí /pushl ‚Üí /copilot ‚Üí /review")
print("- /copilot ‚Üí /execute ‚Üí /commentfetch ‚Üí /fixpr ‚Üí /commentreply")
print("- /execute ‚Üí /plan ‚Üí /think ‚Üí implementation ‚Üí /test")
```

### Step 4: Enhanced Main README.md Update

üö® **MANDATORY STEP**: Update the main README.md (not create variants) with command combination superpowers:

```bash
# Replace the basic export README with comprehensive command showcase
cat > README.md << 'EOF'
# Claude Commands - Command Composition System

‚ö†Ô∏è **REFERENCE EXPORT** - This is a reference export from a working Claude Code project. These commands have been tested in production but may require adaptation for your specific environment. Claude Code excels at helping you customize them for your workflow.

Transform Claude Code into an autonomous development powerhouse through simple command hooks that enable complex workflow orchestration.

## ‚ö° COMMAND COMBINATION SUPERPOWERS

### üéØ Revolutionary Multi-Command Workflows

**Break the One-Command Limit**: Normally, Claude can only handle one command per sentence. This system lets you chain multiple commands in a single prompt, creating sophisticated multi-step workflows.

**Examples**:
- **Comprehensive PR Review**: `/archreview /thinkultra /fake`
  - `/archreview` - Architectural analysis of the codebase
  - `/thinkultra` - Deep strategic thinking about changes  
  - `/fake` - AI-powered detection of placeholder code

- **Complete PR Lifecycle**: `/pr fix the settings button`
  - Automatically runs: `/think` ‚Üí `/execute` ‚Üí `/push` ‚Üí `/copilot` ‚Üí `/review`
  - Full end-to-end automation with zero manual intervention

### ü§ñ AI-Powered Code Quality Detection

**Smart Fake Code Detection**: Built-in `/fake` command uses AI analysis (not just pattern matching) to detect:
- Placeholder implementations that look real but do nothing
- Mock responses without actual logic
- TODOs disguised as complete features  
- Demo code that doesn't actually work

### üîÑ Complete Workflow Automation

**The `/copilot` Advantage**: Responds to GitHub comments and makes fixes automatically, handling the entire feedback loop without manual intervention.

## üöÄ Quick Start Examples

Get started immediately with these powerful command combinations:

```bash
# Comprehensive code analysis
/arch /think /fake

# Full PR workflow automation  
/pr implement user authentication

# Advanced testing with auto-fix
/test all features and if any fail /fix then /copilot
```

[Include rest of enhanced README content with installation, setup, and advanced workflows...]
EOF

echo "‚úÖ Enhanced main README.md with command combination superpowers"
```

üö® **CRITICAL LEARNING**: Always update the actual target file (README.md), never create variants like README_UPDATED.md.

## EXECUTION

**üöÄ PRIMARY EXECUTION PATH**: Use the Python implementation for reliable export
```bash
python3 .claude/commands/exportcommands.py
```

**üß† LLM ENHANCEMENT CAPABILITIES**:
- Generate contextual README sections based on current command inventory
- Analyze command composition patterns for documentation
- Provide intelligent adaptation guidance for different project types
- Generate usage examples tailored to the exported command set

## IMPLEMENTATION EXECUTION

Let me now execute the export using the Python implementation:

```python
import os
import subprocess

# Execute the Python implementation
project_root = subprocess.run(['git', 'rev-parse', '--show-toplevel'],
                            capture_output=True, text=True).stdout.strip()
python_script = os.path.join(project_root, '.claude', 'commands', 'exportcommands.py')

print("üöÄ Starting export via Python implementation...")
result = subprocess.run(['python3', python_script], capture_output=True, text=True)

if result.returncode \!= 0:
    print(f"‚ùå Export failed: {result.stderr}")
    exit(1)

# Print the output (including the critical PR URL)
print(result.stdout)
```

**üö® CRITICAL**: The above execution will print the PR URL as the final output, fulfilling the critical success requirement.

## POST-EXPORT ANALYSIS

After the Python implementation completes, provide intelligent analysis:

```python
# Analyze export results for documentation enhancement
print("\nüìä Export Analysis:")
print("‚úÖ Command composition system exported successfully")
print("‚úÖ Directory exclusions applied per requirements")
print("‚úÖ Content filtering applied for project portability")
print("‚úÖ One-click installation script generated")
print("‚úÖ Comprehensive README with adaptation guide created")
```

**üéØ SUCCESS CRITERIA**:
1. ‚úÖ PR URL printed (handled by Python implementation)
2. ‚úÖ Repository safety maintained (no local changes)
3. ‚úÖ Complete workflow composition system exported
4. ‚úÖ Main README.md updated with COMMAND COMBINATION SUPERPOWERS
5. ‚úÖ Installation automation provided
6. ‚úÖ LLM-enhanced documentation generated
